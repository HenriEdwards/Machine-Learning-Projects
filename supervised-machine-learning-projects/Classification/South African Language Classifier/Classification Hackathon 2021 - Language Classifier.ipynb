{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54239f4b",
   "metadata": {},
   "source": [
    "## Classification Hackathon 2021 - Language Classifier\n",
    "Henri Edwards - Explore Data Science - Class of July 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78e8abd",
   "metadata": {},
   "source": [
    "### 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a76915c",
   "metadata": {},
   "source": [
    "South Africa is a multicultural society that is characterised by its rich linguistic diversity. Language is an indispensable tool that can be used to deepen democracy and also contribute to the social, cultural, intellectual, economic and political life of the South African society.\n",
    "\n",
    "The country is multilingual with 11 official languages, each of which is guaranteed equal status. Most South Africans are multilingual and able to speak at least two or more of the official languages.\n",
    "\n",
    "With such a multilingual population, it is only obvious that our systems and devices also communicate in multi-languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63926d9d",
   "metadata": {},
   "source": [
    "### 2. Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5180e0ac",
   "metadata": {},
   "source": [
    "In this challenge, you will take text which is in any of South Africa's 11 Official languages and identify which language the text is in. This is an example of NLP's Language Identification, the task of determining the natural language that a piece of text is written in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71100c23",
   "metadata": {},
   "source": [
    "### 3. Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1828dc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Prerequisites\n",
    "import sys\n",
    "import nltk\n",
    "\n",
    "# Exploratory Data Analysis\n",
    "import re\n",
    "import ast\n",
    "import time\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data Preprocessing\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk import SnowballStemmer, PorterStemmer, LancasterStemmer\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Classification Model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Performance Evaluation\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a9c60cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore spammy warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fb273a",
   "metadata": {},
   "source": [
    "### 4. Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df262afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_set.csv')\n",
    "test_df = pd.read_csv('test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcb0e7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
       "2     eng  the province of kwazulu-natal department of tr..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View train_df\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa532af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text\n",
       "0      1  Mmasepala, fa maemo a a kgethegileng a letlele...\n",
       "1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2      3         Tshivhumbeo tshi fana na ngano dza vhathu."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View test_df\n",
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af9fc06",
   "metadata": {},
   "source": [
    "### 5. Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c547e5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(text):    \n",
    "    \n",
    "    \"\"\"Function that takes in input text, removes stop words, transforms text to lowercase, removes punctuation and hyperlinks\"\"\"    \n",
    "\n",
    "    stopwords_list = stopwords.words('english')\n",
    "    \n",
    "    text = text.lower() # Changes input text to lowercase for better cleaning\n",
    "    text =  ' '.join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",text).split()) # Remove punctuation\n",
    "    text = re.sub(\"https?:\\/\\/\\S+\", \"\", text) # Remove hyper links\n",
    "    text = ' '.join(word for word in text.split() if word not in stopwords_list) # Remove StopWords\n",
    "    return text    \n",
    "    \n",
    "train_df['text'] = train_df['text'].apply(cleaning) # Apply function to train_df\n",
    "test_df['text'] = test_df['text'].apply(cleaning) # Apply function to test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fab6dba",
   "metadata": {},
   "source": [
    "**Tokenisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "728d0e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(text):\n",
    "    \n",
    "    \"\"\"Function tokenizes input string, and output tokenized text\"\"\"\n",
    "    \n",
    "    text = word_tokenize(text)\n",
    "    return text\n",
    "\n",
    "# Applies function and creates a new feature with function output\n",
    "train_df['tokens'] = train_df['text'].apply(cleaning)\n",
    "test_df['tokens'] = test_df['text'].apply(cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "108dae54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "      <td>[umgaqo, siseko, wenza, amalungiselelo, kumazi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>dha iya kuba nobulumko bokubeka umsebenzi naph...</td>\n",
       "      <td>[dha, iya, kuba, nobulumko, bokubeka, umsebenz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>province kwazulu natal department transport in...</td>\n",
       "      <td>[province, kwazulu, natal, department, transpo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text  \\\n",
       "0     xho  umgaqo siseko wenza amalungiselelo kumaziko ax...   \n",
       "1     xho  dha iya kuba nobulumko bokubeka umsebenzi naph...   \n",
       "2     eng  province kwazulu natal department transport in...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [umgaqo, siseko, wenza, amalungiselelo, kumazi...  \n",
       "1  [dha, iya, kuba, nobulumko, bokubeka, umsebenz...  \n",
       "2  [province, kwazulu, natal, department, transpo...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view tokenized feature\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9381b64",
   "metadata": {},
   "source": [
    "**Stemming**\n",
    "\n",
    "Stemming outperformed lemmitization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1ebc3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(text, stemmer):\n",
    "    \n",
    "    \"\"\"Function performs stemming on a tokenized feature, and outputs a stemmed feature\"\"\"\n",
    "    \n",
    "    return [stemmer.stem(word) for word in text]\n",
    "\n",
    "train_df['stem'] = train_df['tokens'].apply(stemming, args=(stemmer, )) # Apply function to train_df\n",
    "test_df['stem'] = test_df['tokens'].apply(stemming, args=(stemmer, )) # Apply function to test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d49e68fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ListToSentence(text):\n",
    "    \n",
    "    \"\"\"Function converts lists to strings\"\"\"\n",
    "    \n",
    "    return ' '.join(word for word in text)\n",
    "\n",
    "train_df['tokens'] = train_df['tokens'].apply(ListToSentence) # Apply function to train_df\n",
    "train_df['stem'] = train_df['stem'].apply(ListToSentence) # Apply function to train_df\n",
    "\n",
    "test_df['tokens'] = test_df['tokens'].apply(ListToSentence) # Apply function to test_df\n",
    "test_df['stem'] = test_df['stem'].apply(ListToSentence) # Apply function to test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1135e3a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "      <td>umgaqo siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "      <td>umgaqo siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>dha iya kuba nobulumko bokubeka umsebenzi naph...</td>\n",
       "      <td>dha iya kuba nobulumko bokubeka umsebenzi naph...</td>\n",
       "      <td>dha iya kuba nobulumko bokubeka umsebenzi naph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>province kwazulu natal department transport in...</td>\n",
       "      <td>province kwazulu natal department transport in...</td>\n",
       "      <td>provinc kwazulu natal depart transport invit t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text  \\\n",
       "0     xho  umgaqo siseko wenza amalungiselelo kumaziko ax...   \n",
       "1     xho  dha iya kuba nobulumko bokubeka umsebenzi naph...   \n",
       "2     eng  province kwazulu natal department transport in...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  umgaqo siseko wenza amalungiselelo kumaziko ax...   \n",
       "1  dha iya kuba nobulumko bokubeka umsebenzi naph...   \n",
       "2  province kwazulu natal department transport in...   \n",
       "\n",
       "                                                stem  \n",
       "0  umgaqo siseko wenza amalungiselelo kumaziko ax...  \n",
       "1  dha iya kuba nobulumko bokubeka umsebenzi naph...  \n",
       "2  provinc kwazulu natal depart transport invit t...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57228a10",
   "metadata": {},
   "source": [
    "### 6. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a90ea1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33000 entries, 0 to 32999\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   lang_id  33000 non-null  object\n",
      " 1   text     33000 non-null  object\n",
      " 2   tokens   33000 non-null  object\n",
      " 3   stem     33000 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# View all objects\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6f568ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total languages to predict: 11\n"
     ]
    }
   ],
   "source": [
    "# Return total values to predict\n",
    "print('Total languages to predict: '+ str(train_df['lang_id'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66ab1a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['xho', 'eng', 'nso', 'ven', 'tsn', 'nbl', 'zul', 'ssw', 'tso',\n",
       "       'sot', 'afr'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return target values to predict\n",
    "train_df['lang_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f44824c",
   "metadata": {},
   "source": [
    "### 7. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdf52f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign independent variable to X and dependent variable y\n",
    "X = train_df['stem']\n",
    "y = train_df['lang_id']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dc2b757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize X\n",
    "vect = CountVectorizer()\n",
    "X = vect.fit_transform(X)\n",
    "\n",
    "# Splitting train_df into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.01, random_state=42) #using most of the data for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf845b11",
   "metadata": {},
   "source": [
    "#### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2418d31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign algorithm to clf\n",
    "clf = MultinomialNB(alpha=1)\n",
    "\n",
    "# Fit data to MNB model\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85b83f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction on training data\n",
    "y_pred = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "816b5c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       0.96      1.00      0.98        26\n",
      "         eng       1.00      1.00      1.00        36\n",
      "         nbl       1.00      0.96      0.98        25\n",
      "         nso       1.00      1.00      1.00        26\n",
      "         sot       1.00      1.00      1.00        31\n",
      "         ssw       1.00      1.00      1.00        25\n",
      "         tsn       1.00      1.00      1.00        35\n",
      "         tso       1.00      1.00      1.00        21\n",
      "         ven       1.00      1.00      1.00        28\n",
      "         xho       1.00      1.00      1.00        35\n",
      "         zul       1.00      1.00      1.00        42\n",
      "\n",
      "    accuracy                           1.00       330\n",
      "   macro avg       1.00      1.00      1.00       330\n",
      "weighted avg       1.00      1.00      1.00       330\n",
      "\n",
      "F1_score:  0.99642945\n"
     ]
    }
   ],
   "source": [
    "# Print classification report\n",
    "print(metrics.classification_report(y_val, y_pred))\n",
    "\n",
    "# Print f1 score\n",
    "print('F1_score: ',round(metrics.f1_score(y_val, y_pred, average = 'macro'),8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cdb965",
   "metadata": {},
   "source": [
    "### 8. Model Performance\n",
    "Performing hyperparameter tuning using the function GridSearchCV to increase prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "527ada51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1.0, 'class_prior': None, 'fit_prior': True}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View available hyperparameters for MNB algorithm\n",
    "MultinomialNB().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b8de68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter selection for gridsearch\n",
    "alphs = [0.0005, 0.0025, 0.005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1eb196c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.0005}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reference the hyperparameter selection\n",
    "param_grid = {'alpha': alphs}\n",
    "\n",
    "# Assign algorithm to MNB\n",
    "MNB = MultinomialNB()\n",
    "\n",
    "# Assign gridsearch to grid_MNB\n",
    "grid_MNB = GridSearchCV(MNB, param_grid, scoring='f1')\n",
    "\n",
    "# Fit model to training data using Gridsearch\n",
    "grid_MNB.fit(X_train, y_train)\n",
    "\n",
    "# Get best performing hyperparameters\n",
    "grid_MNB.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f351a042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction on train data using best performing hyperparameters\n",
    "y_pred = grid_MNB.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f98769c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00        26\n",
      "         eng       1.00      1.00      1.00        36\n",
      "         nbl       1.00      1.00      1.00        25\n",
      "         nso       1.00      1.00      1.00        26\n",
      "         sot       1.00      1.00      1.00        31\n",
      "         ssw       1.00      1.00      1.00        25\n",
      "         tsn       1.00      1.00      1.00        35\n",
      "         tso       1.00      1.00      1.00        21\n",
      "         ven       1.00      1.00      1.00        28\n",
      "         xho       1.00      1.00      1.00        35\n",
      "         zul       1.00      1.00      1.00        42\n",
      "\n",
      "    accuracy                           1.00       330\n",
      "   macro avg       1.00      1.00      1.00       330\n",
      "weighted avg       1.00      1.00      1.00       330\n",
      "\n",
      "F1_score:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Print classification metrix\n",
    "print(metrics.classification_report(y_val, y_pred))\n",
    "\n",
    "# Print F1 score\n",
    "print('F1_score: ',round(metrics.f1_score(y_val, y_pred, average = 'macro'),8)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6bc31b",
   "metadata": {},
   "source": [
    "### 9. Submission\n",
    "For kaggle submission only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75a4e7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data\n",
    "pred_test_data = grid_MNB.predict(vect.transform(test_df['stem']))\n",
    "pred_df = pd.DataFrame(data=test_df['index'], columns=['index'])\n",
    "pred_df.insert(1, 'lang_id', pred_test_data, allow_duplicates=False)\n",
    "pred_df.to_csv(path_or_buf='Submission.csv', index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
